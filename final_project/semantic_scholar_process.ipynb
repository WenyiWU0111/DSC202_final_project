{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"Machine Learning\",\n",
    "    \"Deep Learning\", \n",
    "    \"Artificial Intelligence\",\n",
    "    \"AI\",\n",
    "    \"Artificial General Intelligence\",\n",
    "    \"AGI\",\n",
    "    \"Large Language Models\",\n",
    "    \"LLMs\", \"VLMs\",\n",
    "    \"Generative Models\",\n",
    "    \"Natural Language Processing\",\n",
    "    \"NLP\",\n",
    "    \"Computer Vision\",\n",
    "    \"Reinforcement Learning\",\n",
    "    \"Big Data\",\n",
    "    \"Data Mining\",\n",
    "    \"Explainable AI\",\n",
    "    \"XAI\",\n",
    "    \"Interpretable Machine Learning\",\n",
    "    \"Graph Neural Networks\",\n",
    "    \"Bayesian Inference\",\n",
    "    \"Causal Inference\",\n",
    "    \"Causal Discovery\",\n",
    "    \"Foundation Models\",\n",
    "    \"Self-Supervised Learning\",\n",
    "    \"Multi-Agent Systems\",\n",
    "    \"Ethics and Bias in AI\"\n",
    "]\n",
    "filenames = [f'/Users/wwy/Documents/UCSD/DSC202/final_project/semanticscholar_data/{keyword}.json' for keyword in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paperId', 'title', 'citationCount', 'citations'])\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "with open(filenames[0], 'r') as f:\n",
    "    data = json.load(f)['data']\n",
    "    print(data[0].keys())\n",
    "    print(len(data[0]['citations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def combine_json_files(json_directory):\n",
    "    # Prepare containers for database structures\n",
    "    all_papers = {}  # Using dict to ensure paper uniqueness\n",
    "    citations = []\n",
    "    keywords = []\n",
    "    paper_keywords = []\n",
    "    authors = {}  # Using dict with authorId as key\n",
    "    paper_authors = []\n",
    "    \n",
    "    def process_authors(paper_id, author_list):\n",
    "        paper_author_rels = []\n",
    "        for author in author_list:\n",
    "            author_id = author.get('authorId')\n",
    "            author_name = author.get('name')\n",
    "            \n",
    "            if not author_id or not author_name:\n",
    "                continue\n",
    "                \n",
    "            # Add author if not already added\n",
    "            if author_id not in authors:\n",
    "                authors[author_id] = {\n",
    "                    'author_id': author_id,\n",
    "                    'name': author_name\n",
    "                }\n",
    "            \n",
    "            paper_author_rels.append({\n",
    "                'paper_id': paper_id,\n",
    "                'author_id': author_id\n",
    "            })\n",
    "        return paper_author_rels\n",
    "    \n",
    "    # Process each JSON file\n",
    "    for json_file in Path(json_directory).glob('*.json'):\n",
    "        keyword = json_file.stem\n",
    "        keywords.append({\n",
    "            'keyword_id': len(keywords) + 1,\n",
    "            'keyword': keyword\n",
    "        })\n",
    "        keyword_id = len(keywords)\n",
    "        \n",
    "        # Load JSON data\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            papers = json.load(f)['data']\n",
    "            \n",
    "        # Process each paper\n",
    "        for paper in papers:\n",
    "            paper_id = paper.get('paperId')\n",
    "            \n",
    "            # Add paper if not already added\n",
    "            if paper_id not in all_papers:\n",
    "                all_papers[paper_id] = {\n",
    "                    'paper_id': paper_id,\n",
    "                    'title': paper.get('title'),\n",
    "                    'citation_count': paper.get('citationCount')\n",
    "                }\n",
    "                \n",
    "                # Process authors for main paper\n",
    "                paper_authors.extend(process_authors(paper_id, paper.get('authors', [])))\n",
    "            \n",
    "            # Add paper-keyword relationship\n",
    "            paper_keywords.append({\n",
    "                'paper_id': paper_id,\n",
    "                'keyword_id': keyword_id\n",
    "            })\n",
    "            \n",
    "            # Process citations\n",
    "            for citation in paper.get('citations', []):\n",
    "                cited_paper_id = citation.get('paperId')\n",
    "                \n",
    "                # Add cited paper if new\n",
    "                if cited_paper_id not in all_papers:\n",
    "                    all_papers[cited_paper_id] = {\n",
    "                        'paper_id': cited_paper_id,\n",
    "                        'title': citation.get('title'),\n",
    "                        'citation_count': citation.get('citationCount')\n",
    "                    }\n",
    "                    \n",
    "                    # Process authors for cited paper\n",
    "                    paper_authors.extend(process_authors(cited_paper_id, citation.get('authors', [])))\n",
    "                \n",
    "                # Add citation relationship\n",
    "                citations.append({\n",
    "                    'cited_paper_id': paper_id,\n",
    "                    'citing_paper_id': cited_paper_id\n",
    "                })\n",
    "    \n",
    "    return {\n",
    "        'papers': list(all_papers.values()),\n",
    "        'citations': citations,\n",
    "        'keywords': keywords,\n",
    "        'paper_keywords': paper_keywords,\n",
    "        'authors': list(authors.values()),\n",
    "        'paper_authors': paper_authors\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_for_databases(combined_data, output_dir='/Users/wwy/Documents/UCSD/DSC202/final_project/database_files'):\n",
    "    # Create output directories\n",
    "    sql_dir = Path(output_dir) / 'sql'\n",
    "    neo4j_dir = Path(output_dir) / 'neo4j'\n",
    "    sql_dir.mkdir(parents=True, exist_ok=True)\n",
    "    neo4j_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save SQL-ready files\n",
    "    pd.DataFrame(combined_data['papers']).to_csv(\n",
    "        sql_dir / 'papers.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(combined_data['citations']).to_csv(\n",
    "        sql_dir / 'citations.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(combined_data['keywords']).to_csv(\n",
    "        sql_dir / 'keywords.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(combined_data['paper_keywords']).to_csv(\n",
    "        sql_dir / 'paper_keywords.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(combined_data['authors']).to_csv(\n",
    "        sql_dir / 'authors.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(combined_data['paper_authors']).to_csv(\n",
    "        sql_dir / 'paper_authors.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # Save Neo4j-ready files\n",
    "    pd.DataFrame(combined_data['papers']).to_csv(\n",
    "        neo4j_dir / 'papers.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(combined_data['citations']).to_csv(\n",
    "        neo4j_dir / 'citations.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(combined_data['authors']).to_csv(\n",
    "        neo4j_dir / 'authors.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    pd.DataFrame(combined_data['paper_authors']).to_csv(\n",
    "        neo4j_dir / 'paper_authors.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    # Keywords and relationships for Neo4j\n",
    "    keyword_relationships = []\n",
    "    for pk in combined_data['paper_keywords']:\n",
    "        keyword = next(k['keyword'] for k in combined_data['keywords'] \n",
    "                      if k['keyword_id'] == pk['keyword_id'])\n",
    "        keyword_relationships.append({\n",
    "            'paper_id': pk['paper_id'],\n",
    "            'keyword': keyword\n",
    "        })\n",
    "    \n",
    "    pd.DataFrame(keyword_relationships).to_csv(\n",
    "        neo4j_dir / 'keyword_relationships.csv',\n",
    "        index=False,\n",
    "        encoding='utf-8'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_database_scripts(output_dir):\n",
    "    # SQL creation script\n",
    "    sql_script = \"\"\"\n",
    "CREATE TABLE papers (\n",
    "    paper_id VARCHAR(255) PRIMARY KEY,\n",
    "    title TEXT NOT NULL,\n",
    "    citation_count INTEGER,\n",
    "    abstract TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE authors (\n",
    "    author_id VARCHAR(255) PRIMARY KEY,  -- Changed to VARCHAR for semantic scholar authorId\n",
    "    name VARCHAR(255) NOT NULL\n",
    ");\n",
    "\n",
    "CREATE TABLE paper_authors (\n",
    "    paper_id VARCHAR(255),\n",
    "    author_id VARCHAR(255),  -- Changed to VARCHAR\n",
    "    PRIMARY KEY (paper_id, author_id),\n",
    "    FOREIGN KEY (paper_id) REFERENCES papers(paper_id),\n",
    "    FOREIGN KEY (author_id) REFERENCES authors(author_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE keywords (\n",
    "    keyword_id INTEGER PRIMARY KEY,\n",
    "    keyword VARCHAR(255) NOT NULL UNIQUE\n",
    ");\n",
    "\n",
    "CREATE TABLE paper_keywords (\n",
    "    paper_id VARCHAR(255),\n",
    "    keyword_id INTEGER,\n",
    "    PRIMARY KEY (paper_id, keyword_id),\n",
    "    FOREIGN KEY (paper_id) REFERENCES papers(paper_id),\n",
    "    FOREIGN KEY (keyword_id) REFERENCES keywords(keyword_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE citations (\n",
    "    citing_paper_id VARCHAR(255),\n",
    "    cited_paper_id VARCHAR(255),\n",
    "    PRIMARY KEY (citing_paper_id, cited_paper_id),\n",
    "    FOREIGN KEY (citing_paper_id) REFERENCES papers(paper_id),\n",
    "    FOREIGN KEY (cited_paper_id) REFERENCES papers(paper_id)\n",
    ");\n",
    "\n",
    "CREATE INDEX idx_papers_citation_count ON papers(citation_count);\n",
    "CREATE INDEX idx_papers_title ON papers(title);\n",
    "CREATE INDEX idx_authors_name ON authors(name);\n",
    "CREATE INDEX idx_keywords_keyword ON keywords(keyword);\n",
    "\"\"\"\n",
    "\n",
    "    # Neo4j creation script\n",
    "    neo4j_script = \"\"\"\n",
    "// Create constraints\n",
    "CREATE CONSTRAINT paper_id IF NOT EXISTS ON (p:Paper) ASSERT p.paper_id IS UNIQUE;\n",
    "CREATE CONSTRAINT author_id IF NOT EXISTS ON (a:Author) ASSERT a.author_id IS UNIQUE;\n",
    "CREATE CONSTRAINT keyword_name IF NOT EXISTS ON (k:Keyword) ASSERT k.name IS UNIQUE;\n",
    "\n",
    "// Load papers\n",
    "LOAD CSV WITH HEADERS FROM 'file:///papers.csv' AS row\n",
    "CREATE (p:Paper {\n",
    "    paper_id: row.paper_id,\n",
    "    title: row.title,\n",
    "    citation_count: toInteger(row.citation_count),\n",
    "    abstract: row.abstract\n",
    "});\n",
    "\n",
    "// Load authors\n",
    "LOAD CSV WITH HEADERS FROM 'file:///authors.csv' AS row\n",
    "CREATE (a:Author {\n",
    "    author_id: row.author_id,\n",
    "    name: row.name\n",
    "});\n",
    "\n",
    "// Load paper-author relationships\n",
    "LOAD CSV WITH HEADERS FROM 'file:///paper_authors.csv' AS row\n",
    "MATCH (p:Paper {paper_id: row.paper_id})\n",
    "MATCH (a:Author {author_id: row.author_id})\n",
    "CREATE (p)-[:AUTHORED_BY]->(a);\n",
    "\n",
    "// Load citations\n",
    "LOAD CSV WITH HEADERS FROM 'file:///citations.csv' AS row\n",
    "MATCH (citing:Paper {paper_id: row.citing_paper_id})\n",
    "MATCH (cited:Paper {paper_id: row.cited_paper_id})\n",
    "CREATE (citing)-[:CITES]->(cited);\n",
    "\n",
    "// Load keywords and relationships\n",
    "LOAD CSV WITH HEADERS FROM 'file:///keyword_relationships.csv' AS row\n",
    "MATCH (p:Paper {paper_id: row.paper_id})\n",
    "MERGE (k:Keyword {name: row.keyword})\n",
    "CREATE (p)-[:HAS_KEYWORD]->(k);\n",
    "\n",
    "// Create indexes\n",
    "CREATE INDEX paper_citation_idx IF NOT EXISTS FOR (p:Paper) ON (p.citation_count);\n",
    "CREATE INDEX paper_title_idx IF NOT EXISTS FOR (p:Paper) ON (p.title);\n",
    "CREATE INDEX author_name_idx IF NOT EXISTS FOR (a:Author) ON (a.name);\n",
    "\"\"\"\n",
    "\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    with open(Path(output_dir) / 'sql' / 'create_tables.sql', 'w') as f:\n",
    "        f.write(sql_script)\n",
    "    with open(Path(output_dir) / 'neo4j' / 'import_data.cypher', 'w') as f:\n",
    "        f.write(neo4j_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files processed and saved successfully!\n",
      "Total papers: 130740\n",
      "Total citations: 168511\n",
      "Total authors: 477314\n",
      "Total keywords: 27\n"
     ]
    }
   ],
   "source": [
    "json_dir = \"/Users/wwy/Documents/UCSD/DSC202/final_project/semanticscholar_json\"\n",
    "output_dir = \"/Users/wwy/Documents/UCSD/DSC202/final_project/database_files\"\n",
    "\n",
    "combined_data = combine_json_files(json_dir)\n",
    "save_for_databases(combined_data, output_dir)\n",
    "generate_database_scripts(output_dir)\n",
    "\n",
    "print(\"Files processed and saved successfully!\")\n",
    "print(f\"Total papers: {len(combined_data['papers'])}\")\n",
    "print(f\"Total citations: {len(combined_data['citations'])}\")\n",
    "print(f\"Total authors: {len(combined_data['authors'])}\")\n",
    "print(f\"Total keywords: {len(combined_data['keywords'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_asbf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
